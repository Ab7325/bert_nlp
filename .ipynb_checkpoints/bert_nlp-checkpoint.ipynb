{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8690d3d",
   "metadata": {},
   "source": [
    "#BERT NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4bde2a",
   "metadata": {},
   "source": [
    "##1 Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f742f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, BertForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae96a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99786a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bert tokeniser\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa84aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample texts\n",
    "text_1 = \"I am good at both chess and boxing\"\n",
    "text_2 = \"What am I good at?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aecf4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization with special tokens: [CLS] at beginning and [SEP] at end\n",
    "indexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)\n",
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137eacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(indexed_tokens)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd548f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = tokenizer.decode(indexed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54bfa14",
   "metadata": {},
   "source": [
    "##Segmentation of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d854753",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_token_id = tokenizer.cls_token_id  # [CLS] token\n",
    "sep_token_id = tokenizer.sep_token_id  # [SEP] token\n",
    "cls_token_id\n",
    "sep_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3f896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_ids(indexed_tokens, sep_token_id=102):\n",
    "    \"\"\"\n",
    "    Create segment IDs to distinguish between different text segments.\n",
    "    \n",
    "    Args:\n",
    "        indexed_tokens: List of token IDs\n",
    "        sep_token_id: ID of the separator token\n",
    "        \n",
    "    Returns:\n",
    "        segment_ids_tensor: Tensor of segment IDs\n",
    "        tokens_tensor: Tensor of token IDs\n",
    "    \"\"\"\n",
    "    segment_ids = []\n",
    "    segment_id = 0\n",
    "    \n",
    "    for token in indexed_tokens:\n",
    "        if token == sep_token_id:\n",
    "            segment_id += 1\n",
    "        segment_ids.append(segment_id)\n",
    "    \n",
    "    # Last [SEP] token is not considered\n",
    "    segment_ids[-1] = segment_ids[-1] - 1\n",
    "    \n",
    "    # Convert to tensors\n",
    "    segment_ids_tensor = torch.tensor([segment_ids]).to(device)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "    \n",
    "    return segment_ids_tensor, tokens_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764de907",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_tensors, tokens_tensor = get_segment_ids(indexed_tokens, sep_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95c57e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 3))\n",
    "plt.bar(range(len(tokens)), segments_tensors[0].cpu().numpy(), align='center')\n",
    "plt.xticks(range(len(tokens)), tokens, rotation=45)\n",
    "plt.ylabel('Segment ID')\n",
    "plt.title('Token Segmentation')\n",
    "plt.tight_layout()\n",
    "plt.savefig('token_segmentation.png')  # Save the figure if needed\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
